{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97253d92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv('../data/solar_data.csv')\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "# 2. Data Overview\n",
    "print(\"=== DATA OVERVIEW ===\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# 3. Summary Statistics & Missing Values\n",
    "print(\"=== SUMMARY STATISTICS ===\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing_data = df.isna().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_report = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "print(missing_report)\n",
    "\n",
    "# Identify columns with >5% nulls\n",
    "high_missing = missing_report[missing_report['Missing Percentage'] > 5]\n",
    "print(f\"\\nColumns with >5% missing values: {high_missing.index.tolist()}\")\n",
    "\n",
    "# 4. Outlier Detection using Z-scores\n",
    "print(\"=== OUTLIER DETECTION ===\")\n",
    "numeric_cols = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "z_scores = np.abs(stats.zscore(df[numeric_cols].dropna()))\n",
    "outliers = (z_scores > 3).any(axis=1)\n",
    "print(f\"Number of outlier rows: {outliers.sum()}\")\n",
    "\n",
    "# 5. Data Cleaning\n",
    "print(\"=== DATA CLEANING ===\")\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Handle missing values in key columns\n",
    "key_columns = ['GHI', 'DNI', 'DHI', 'Tamb', 'RH', 'WS']\n",
    "for col in key_columns:\n",
    "    if col in df_clean.columns:\n",
    "        median_val = df_clean[col].median()\n",
    "        df_clean[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Remove outliers\n",
    "df_clean = df_clean[~outliers]\n",
    "\n",
    "print(f\"Original data shape: {df.shape}\")\n",
    "print(f\"Cleaned data shape: {df_clean.shape}\")\n",
    "\n",
    "# 6. Time Series Analysis\n",
    "print(\"=== TIME SERIES ANALYSIS ===\")\n",
    "df_clean['Timestamp'] = pd.to_datetime(df_clean['Timestamp'])\n",
    "df_clean.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Plot time series\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "df_clean['GHI'].resample('D').mean().plot(ax=axes[0,0], title='Daily Average GHI')\n",
    "df_clean['DNI'].resample('D').mean().plot(ax=axes[0,1], title='Daily Average DNI')\n",
    "df_clean['DHI'].resample('D').mean().plot(ax=axes[1,0], title='Daily Average DHI')\n",
    "df_clean['Tamb'].resample('D').mean().plot(ax=axes[1,1], title='Daily Average Temperature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Cleaning Impact Analysis\n",
    "print(\"=== CLEANING IMPACT ===\")\n",
    "if 'Cleaning' in df_clean.columns:\n",
    "    cleaning_impact = df_clean.groupby('Cleaning')[['ModA', 'ModB']].mean()\n",
    "    print(cleaning_impact)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    cleaning_impact['ModA'].plot(kind='bar', ax=axes[0], title='ModA - Pre/Post Cleaning')\n",
    "    cleaning_impact['ModB'].plot(kind='bar', ax=axes[1], title='ModB - Pre/Post Cleaning')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 8. Correlation Analysis\n",
    "print(\"=== CORRELATION ANALYSIS ===\")\n",
    "corr_cols = ['GHI', 'DNI', 'DHI', 'TModA', 'TModB', 'Tamb', 'RH', 'WS']\n",
    "corr_matrix = df_clean[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# 9. Scatter Plots\n",
    "print(\"=== RELATIONSHIP ANALYSIS ===\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "df_clean.plot.scatter(x='WS', y='GHI', ax=axes[0,0], alpha=0.5, title='WS vs GHI')\n",
    "df_clean.plot.scatter(x='RH', y='Tamb', ax=axes[0,1], alpha=0.5, title='RH vs Temperature')\n",
    "df_clean.plot.scatter(x='RH', y='GHI', ax=axes[1,0], alpha=0.5, title='RH vs GHI')\n",
    "df_clean.plot.scatter(x='Tamb', y='GHI', ax=axes[1,1], alpha=0.5, title='Temperature vs GHI')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 10. Distribution Analysis\n",
    "print(\"=== DISTRIBUTION ANALYSIS ===\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "df_clean['GHI'].hist(ax=axes[0,0], bins=50)\n",
    "axes[0,0].set_title('GHI Distribution')\n",
    "df_clean['WS'].hist(ax=axes[0,1], bins=50)\n",
    "axes[0,1].set_title('Wind Speed Distribution')\n",
    "df_clean['Tamb'].hist(ax=axes[1,0], bins=50)\n",
    "axes[1,0].set_title('Temperature Distribution')\n",
    "df_clean['RH'].hist(ax=axes[1,1], bins=50)\n",
    "axes[1,1].set_title('Relative Humidity Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 11. Bubble Chart\n",
    "print(\"=== BUBBLE CHART ===\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(df_clean['Tamb'], df_clean['GHI'], \n",
    "                     c=df_clean['RH'], s=df_clean['BP']/10, \n",
    "                     alpha=0.6, cmap='viridis')\n",
    "plt.colorbar(scatter, label='Relative Humidity (%)')\n",
    "plt.xlabel('Temperature (°C)')\n",
    "plt.ylabel('GHI (W/m²)')\n",
    "plt.title('GHI vs Temperature (Bubble size = BP, Color = RH)')\n",
    "plt.show()\n",
    "\n",
    "# 12. Save Cleaned Data\n",
    "df_clean.reset_index(inplace=True)\n",
    "df_clean.to_csv('../data/benin_clean.csv', index=False)\n",
    "print(\"Cleaned data saved to ../data/benin_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
